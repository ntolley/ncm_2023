{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pickle\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import contrastive_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/Donoghue_lab/ncm_2023/notebooks/../code/contrastive_functions.py:332: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neural_temp_df['rates'][unit_mask] = noise_data\n",
      "/home/nick/Donoghue_lab/ncm_2023/notebooks/../code/contrastive_functions.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wrist_temp_df['posData'][unit_mask] = noise_data\n",
      "/home/nick/Donoghue_lab/ncm_2023/notebooks/../code/contrastive_functions.py:332: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neural_temp_df['rates'][unit_mask] = noise_data\n",
      "/home/nick/Donoghue_lab/ncm_2023/notebooks/../code/contrastive_functions.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wrist_temp_df['posData'][unit_mask] = noise_data\n"
     ]
    }
   ],
   "source": [
    "noise_fold = 0\n",
    "data_dict = contrastive_functions.get_marker_decode_dataframes(noise_fold = noise_fold)\n",
    "wrist_df = data_dict['wrist_df']\n",
    "task_neural_df = data_dict['task_neural_df']\n",
    "notask_neural_df = data_dict['notask_neural_df']\n",
    "metadata = data_dict['metadata']\n",
    "cv_dict = data_dict['cv_dict']\n",
    "\n",
    "neuron_list = notask_neural_df['unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_offset = 10 # try 50-150 ms offset\n",
    "window_size = 70\n",
    "label_col = 'layout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiener_task num_neurons: 2; repeat 0\n",
      "wiener_notask num_neurons: 2; repeat 0\n",
      "rnn_task num_neurons: 2; repeat 0\n",
      "**********\n",
      "Epoch: 10/1000 ... Train Loss: 1.5179  ... Validation Loss: 1.4204\n",
      "***"
     ]
    }
   ],
   "source": [
    "func_dict = {'wiener': contrastive_functions.run_wiener, 'rnn': contrastive_functions.run_rnn}\n",
    "\n",
    "fpath = '../data/SPK20220308/neuron_num_results/'\n",
    "\n",
    "num_repeats = 5\n",
    "# num_neuron_list = np.arange(2,51,4)\n",
    "num_neuron_list = [2,4,6,10,15,20]\n",
    "# num_neuron_list = [30,40]\n",
    "\n",
    "\n",
    "num_neuron_results_dict = {'num_neuron_list': num_neuron_list, 'num_repeats': num_repeats, 'moise_fold': noise_fold}\n",
    "for repeat_idx in range(num_repeats):\n",
    "    rng = np.random.default_rng(repeat_idx) # new set of shuffled neurons seeded by repeat_idx\n",
    "    random_units = rng.choice(range(85), size=85).astype(str)\n",
    "\n",
    "    num_neuron_results_dict[f'repeat_{repeat_idx}'] = {'random_units': random_units}\n",
    "    for num_neurons in num_neuron_list:\n",
    "        # Filter neural_df with task info to random subset of neurons\n",
    "        task_unit_mask = np.in1d(task_neural_df['unit'].values, random_units[:num_neurons])\n",
    "        layout_mask = task_neural_df['unit'].str.contains(pat='layout')\n",
    "\n",
    "        task_neural_df_filtered = task_neural_df[np.logical_or.reduce([task_unit_mask, layout_mask])].reset_index(drop=True)\n",
    "\n",
    "        # Filter neural_df without task info to random subset of neurons\n",
    "        notask_unit_mask = np.in1d(notask_neural_df['unit'].values, random_units[:num_neurons])\n",
    "        notask_neural_df_filtered = notask_neural_df[np.logical_or.reduce([notask_unit_mask])].reset_index(drop=True)\n",
    "\n",
    "        df_dict = {'task': {'df': task_neural_df_filtered, 'task_info': True, 'num_cat': 4}, # num_cat = number of categorical features\n",
    "                   'notask': {'df': notask_neural_df_filtered, 'task_info': False, 'num_cat': 0}}\n",
    "        \n",
    "\n",
    "        decode_results = dict()\n",
    "        for func_name, func in func_dict.items():\n",
    "            decode_results[func_name] = dict()\n",
    "            for df_type, pred_df in df_dict.items():\n",
    "                print(f'{func_name}_{df_type} num_neurons: {num_neurons}; repeat {repeat_idx}')\n",
    "\n",
    "                model, res_dict = func(wrist_df, pred_df['df'], neural_offset, cv_dict, metadata, task_info=pred_df['task_info'],\n",
    "                                       window_size=window_size, num_cat=pred_df['num_cat'], label_col=label_col)\n",
    "\n",
    "                decode_results[func_name][df_type] = res_dict\n",
    "\n",
    "                # Save results on every loop in case early stop\n",
    "                num_neuron_results_dict[f'repeat_{repeat_idx}'][f'num_neuron_{num_neurons}'] = decode_results\n",
    "                #Save metadata\n",
    "                output = open(f'{fpath}num_neuron_results.pkl', 'wb')\n",
    "                pickle.dump(num_neuron_results_dict, output)\n",
    "                output.close()\n",
    "\n",
    "                if func_name == 'rnn':\n",
    "                    torch.save(model.state_dict(), f'{fpath}models/{df_type}_neurons{num_neurons}_repeat{repeat_idx}.pt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b48ab3240dc41ffa029ce879fa5e087e0a83cbe7a72ef65a19cb71535771faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
